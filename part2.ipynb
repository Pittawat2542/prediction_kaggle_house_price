{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/train.csv').fillna(method='ffill')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_column(encoded_dataset):\n",
    "    encoded_dataset['MSZoning'] = encoded_dataset['MSZoning'].replace({'A': 0, 'C': 1, 'C (all)': 1, 'FV': 2, 'I': 3, 'RH': 4, 'RL': 5, 'RP': 6, 'RM': 7 }).astype(int)\n",
    "    encoded_dataset['Street'] = encoded_dataset['Street'].replace({'Grvl': 0, 'Pave': 1 }).astype(int)\n",
    "    encoded_dataset['Alley'] = encoded_dataset['Alley'].replace({'Grvl': 0, 'Pave': 1, 'NA': 2 }).astype(int)\n",
    "    encoded_dataset['LotShape'] = encoded_dataset['LotShape'].replace({'Reg': 0, 'IR1': 1, 'IR2': 2, 'IR3': 3 }).astype(int)\n",
    "    encoded_dataset['LandContour'] = encoded_dataset['LandContour'].replace({'Lvl': 0, 'Bnk': 1, 'HLS': 2, 'Low': 3 }).astype(int)\n",
    "    encoded_dataset['Utilities'] = encoded_dataset['Utilities'].replace({'AllPub': 0, 'NoSewr': 1, 'NoSeWa': 2, 'ELO': 3 }).astype(int)\n",
    "    encoded_dataset['LotConfig'] = encoded_dataset['LotConfig'].replace({'Inside': 0, 'Corner': 1, 'CulDSac': 2, 'FR2': 3, 'FR3': 4 }).astype(int)\n",
    "    encoded_dataset['LandSlope'] = encoded_dataset['LandSlope'].replace({'Gtl': 0, 'Mod': 1, 'Sev': 2 }).astype(int)\n",
    "    encoded_dataset['Neighborhood'] = encoded_dataset['Neighborhood'].replace({'Blmngtn': 0, 'Blueste': 1, 'BrDale': 2, 'BrkSide': 3, 'ClearCr': 4, 'CollgCr': 5, 'Crawfor': 6, 'Edwards': 7, 'Gilbert': 8, 'IDOTRR': 9, 'MeadowV': 10, 'Mitchel': 11, 'Names': 12, 'NAmes': 12, 'NoRidge': 13, 'NPkVill': 14, 'NridgHt': 15, 'NWAmes': 16, 'OldTown': 17, 'SWISU': 18, 'Sawyer': 19, 'SawyerW': 20, 'Somerst': 21, 'StoneBr': 22, 'Timber': 23, 'Veenker': 24 }).astype(int)\n",
    "    encoded_dataset['Condition1'] = encoded_dataset['Condition1'].replace({'Artery': 0, 'Feedr': 1, 'Norm': 2, 'RRNn': 3, 'RRAn': 4, 'PosN': 5, 'PosA': 6, 'RRNe': 7, 'RRAe': 8 }).astype(int)\n",
    "    encoded_dataset['Condition2'] = encoded_dataset['Condition2'].replace({'Artery': 0, 'Feedr': 1, 'Norm': 2, 'RRNn': 3, 'RRAn': 4, 'PosN': 5, 'PosA': 6, 'RRNe': 7, 'RRAe': 8 }).astype(int)\n",
    "    encoded_dataset['BldgType'] = encoded_dataset['BldgType'].replace({'1Fam': 0, '2FmCon': 1, '2fmCon': 1, 'Duplx': 2, 'Duplex': 2, 'TwnhsE': 3, 'Twnhs': 3, 'TwnhsI': 4 }).astype(int)\n",
    "    encoded_dataset['HouseStyle'] = encoded_dataset['HouseStyle'].replace({'1Story': 0, '1.5Fin': 1, '1.5Unf': 2, '2Story': 3, '2.5Fin': 4, '2.5Unf': 5, 'SFoyer': 6, 'SLvl': 7 }).astype(int)\n",
    "    encoded_dataset['RoofStyle'] = encoded_dataset['RoofStyle'].replace({'Flat': 0, 'Gable': 1, 'Gambrel': 2, 'Hip': 3, 'Mansard': 4, 'Shed': 5 }).astype(int)\n",
    "    encoded_dataset['RoofMatl'] = encoded_dataset['RoofMatl'].replace({'ClyTile': 0, 'CompShg': 1, 'Membran': 2, 'Metal': 3, 'Roll': 4, 'Tar&Grv': 5, 'WdShake': 6, 'WdShngl': 7 }).astype(int)\n",
    "    encoded_dataset['Exterior1st'] = encoded_dataset['Exterior1st'].replace({'AsbShng': 0, 'AsphShn': 1, 'BrkComm': 2, 'Brk Cmn': 2, 'BrkFace': 3, 'CBlock': 4, 'CemntBd': 5, 'CmentBd': 5, 'HdBoard': 6, 'ImStucc': 7, 'MetalSd': 8, 'Other': 9, 'Plywood': 10, 'PreCase': 11, 'Stone': 12, 'Stucco': 13, 'VinylSd': 14, 'Wd Sdng': 15, 'WdShing': 16, 'Wd Shng': 17 }).astype(int)\n",
    "    encoded_dataset['Exterior2nd'] = encoded_dataset['Exterior2nd'].replace({'AsbShng': 0, 'AsphShn': 1, 'BrkComm': 2, 'Brk Cmn': 2, 'BrkFace': 3, 'CBlock': 4, 'CemntBd': 5, 'CmentBd': 5, 'HdBoard': 6, 'ImStucc': 7, 'MetalSd': 8, 'Other': 9, 'Plywood': 10, 'PreCase': 11, 'Stone': 12, 'Stucco': 13, 'VinylSd': 14, 'Wd Sdng': 15, 'WdShing': 16, 'Wd Shng': 17 }).astype(int)\n",
    "    encoded_dataset['MasVnrType'] = encoded_dataset['MasVnrType'].replace({'BrkCmn': 0, 'BrkFace': 1, 'CBlock': 2, 'None': 3, 'Stone': 4 }).astype(int)\n",
    "    encoded_dataset['ExterQual'] = encoded_dataset['ExterQual'].replace({'Ex': 0, 'Gd': 1, 'TA': 2, 'Fa': 3, 'Po': 4 }).astype(int)\n",
    "    encoded_dataset['ExterCond'] = encoded_dataset['ExterCond'].replace({'Ex': 0, 'Gd': 1, 'TA': 2, 'Fa': 3, 'Po': 4 }).astype(int)\n",
    "    encoded_dataset['Foundation'] = encoded_dataset['Foundation'].replace({'BrkTil': 0, 'CBlock': 1, 'PConc': 2, 'Slab': 3, 'Stone': 4, 'Wood': 5 }).astype(int)\n",
    "    encoded_dataset['BsmtQual'] = encoded_dataset['BsmtQual'].replace({'Ex': 0, 'Gd': 1, 'TA': 2, 'Fa': 3, 'Po': 4, 'NA': 5 }).astype(int)\n",
    "    encoded_dataset['BsmtCond'] = encoded_dataset['BsmtCond'].replace({'Ex': 0, 'Gd': 1, 'TA': 2, 'Fa': 3, 'Po': 4, 'NA': 5 }).astype(int)\n",
    "    encoded_dataset['BsmtExposure'] = encoded_dataset['BsmtExposure'].replace({'Gd': 0, 'Av': 1, 'Mn': 2, 'No': 3, 'NA': 5 }).astype(int)\n",
    "    encoded_dataset['BsmtFinType1'] = encoded_dataset['BsmtFinType1'].replace({'GLQ': 0, 'ALQ': 1, 'BLQ': 2, 'Rec': 3, 'LwQ': 4, 'Unf': 5, 'NA': 6 }).astype(int)\n",
    "    encoded_dataset['BsmtFinType2'] = encoded_dataset['BsmtFinType2'].replace({'GLQ': 0, 'ALQ': 1, 'BLQ': 2, 'Rec': 3, 'LwQ': 4, 'Unf': 5, 'NA': 6 }).astype(int)\n",
    "    encoded_dataset['Heating'] = encoded_dataset['Heating'].replace({'Floor': 0, 'GasA': 1, 'GasW': 2, 'Grav': 3, 'OthW': 4, 'Wall': 5 }).astype(int)\n",
    "    encoded_dataset['HeatingQC'] = encoded_dataset['HeatingQC'].replace({'Ex': 0, 'Gd': 1, 'TA': 2, 'Fa': 3, 'Po': 4 }).astype(int)\n",
    "    encoded_dataset['CentralAir'] = encoded_dataset['CentralAir'].replace({'N': 0, 'Y': 1 }).astype(int)\n",
    "    encoded_dataset['Electrical'] = encoded_dataset['Electrical'].replace({'SBrkr': 0, 'FuseA': 1, 'FuseF': 2, 'FuseP': 3, 'Mix': 4 }).astype(int)\n",
    "    encoded_dataset['KitchenQual'] = encoded_dataset['KitchenQual'].replace({'Ex': 0, 'Gd': 1, 'TA': 2, 'Fa': 3, 'Po': 4 }).astype(int)\n",
    "    encoded_dataset['Functional'] = encoded_dataset['Functional'].replace({'Typ': 0, 'Min1': 1, 'Min2': 2, 'Mod': 3, 'Maj1': 4, 'Maj2': 5, 'Sev': 6, 'Sal': 7 }).astype(int) \n",
    "    encoded_dataset['FireplaceQu'] = encoded_dataset['FireplaceQu'].replace({'Ex': 0, 'Gd': 1, 'TA': 2, 'Fa': 3, 'Po': 4, 'NA': 5 }).astype(int)\n",
    "    encoded_dataset['GarageType'] = encoded_dataset['GarageType'].replace({'2Types': 0, 'Attchd': 1, 'Basment': 2, 'BuiltIn': 3, 'CarPort': 4, 'Detchd': 5, 'NA': 6 }).astype(int)\n",
    "    encoded_dataset['GarageFinish'] = encoded_dataset['GarageFinish'].replace({'Fin': 0, 'RFn': 1, 'Unf': 2, 'NA': 3 }).astype(int)\n",
    "    encoded_dataset['GarageQual'] = encoded_dataset['GarageQual'].replace({'Ex': 0, 'Gd': 1, 'TA': 2, 'Fa': 3, 'Po': 4, 'NA': 5 }).astype(int)\n",
    "    encoded_dataset['GarageCond'] = encoded_dataset['GarageCond'].replace({'Ex': 0, 'Gd': 1, 'TA': 2, 'Fa': 3, 'Po': 4, 'NA': 5 }).astype(int)\n",
    "    encoded_dataset['PavedDrive'] = encoded_dataset['PavedDrive'].replace({'Y': 0, 'P': 1, 'N': 2 }).astype(int)\n",
    "    encoded_dataset['PoolQC'] = encoded_dataset['PoolQC'].replace({'Ex': 0, 'Gd': 1, 'TA': 2, 'Fa': 3, 'Po': 4, 'NA': 5 }).astype(int)\n",
    "    encoded_dataset['Fence'] = encoded_dataset['Fence'].replace({'GdPrv': 0, 'MnPrv': 1, 'GdWo': 2, 'MnWw': 3, 'NA': 4 }).astype(int)\n",
    "    encoded_dataset['MiscFeature'] = encoded_dataset['MiscFeature'].replace({'Elev': 0, 'Gar2': 1, 'Othr': 2, 'Shed': 3, 'TenC': 4, 'NA': 5 }).astype(int)\n",
    "    encoded_dataset['SaleType'] = encoded_dataset['SaleType'].replace({'WD': 0, 'CWD': 1, 'VWD': 2, 'New': 3, 'COD': 4, 'Con': 5, 'ConLw': 6, 'ConLI': 7, 'ConLD': 8, 'Oth': 9 }).astype(int)\n",
    "    encoded_dataset['SaleCondition'] = encoded_dataset['SaleCondition'].replace({'Normal': 0, 'Abnorml': 1, 'AdjLand': 2, 'Alloca': 3, 'Family': 4, 'Partial': 5 }).astype(int)\n",
    "    return encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = encode_column(dataset.fillna(0))\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(['Id', 'SalePrice'], axis=1).values\n",
    "y = dataset['SalePrice'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = encode_column(pd.read_csv('data/test.csv').fillna(0).drop(['Id'], axis=1))\n",
    "test_dataset.shape\n",
    "\n",
    "test_id = pd.read_csv('data/test.csv').fillna(0)['Id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_features='sqrt', min_samples_split=5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_params = {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
    "\n",
    "random_forest_regressor = RandomForestRegressor(**rf_params)\n",
    "random_forest_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1.0, gamma=0.5, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xg_params = {'colsample_bytree': 1.0, 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8}\n",
    "\n",
    "xgboost = xgb.XGBRegressor(**xg_params)\n",
    "xgboost.fit(X_train, y_train, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_depth=5, max_features='sqrt',\n",
       "                          min_samples_split=10, n_estimators=1000,\n",
       "                          subsample=0.8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb_params = {'learning_rate': 0.01, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 1000, 'subsample': 0.8}\n",
    "\n",
    "gb_regressor = GradientBoostingRegressor(**params)\n",
    "gb_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "models = list()\n",
    "models.append(('gradient_boosting', GradientBoostingRegressor(**gb_params)))\n",
    "models.append(('xgboost', xgb.XGBRegressor(**xg_params)))\n",
    "models.append(('random_forest', RandomForestRegressor(**rf_params)))\n",
    "\n",
    "ensemble = VotingRegressor(estimators=models)\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 16129.159692814941\n",
      "Mean Squared Error: 929528834.5934461\n",
      "Root Mean Squared Error: 30488.17532410633\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = ensemble.predict(test_dataset.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Id': test_id, 'SalePrice': test_pred})\n",
    "df.to_csv('voting-all-encoded-column-tuned.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:   18.8s\n",
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=8)]: Done 226 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=8)]: Done 249 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=8)]: Done 297 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=8)]: Done 322 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=8)]: Done 376 tasks      | elapsed: 23.4min\n",
      "[Parallel(n_jobs=8)]: Done 405 tasks      | elapsed: 26.8min\n",
      "[Parallel(n_jobs=8)]: Done 432 out of 432 | elapsed: 28.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9960451180624581\n",
      "{'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "parameters = { 'bootstrap': [True, False],\n",
    "              'max_depth': [50, 100, None],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2],\n",
    "              'min_samples_split': [2, 5],\n",
    "              'n_estimators': [100, 500, 10000]}\n",
    "\n",
    "clf = GridSearchCV(RandomForestRegressor(), parameters, cv=3, n_jobs=8, verbose=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 405 candidates, totalling 1215 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    2.1s\n",
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=8)]: Done 226 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=8)]: Done 249 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=8)]: Done 297 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=8)]: Done 322 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=8)]: Done 376 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=8)]: Done 405 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=8)]: Done 465 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=8)]: Done 496 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=8)]: Done 529 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=8)]: Done 562 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=8)]: Done 597 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=8)]: Done 632 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=8)]: Done 669 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=8)]: Done 706 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=8)]: Done 745 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=8)]: Done 825 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=8)]: Done 866 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=8)]: Done 909 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=8)]: Done 952 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=8)]: Done 997 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=8)]: Done 1042 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=8)]: Done 1089 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=8)]: Done 1136 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=8)]: Done 1185 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=8)]: Done 1215 out of 1215 | elapsed:   38.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9989969806114242\n",
      "{'colsample_bytree': 1.0, 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "parameters = { 'min_child_weight': [1, 5, 10],\n",
    "              'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "              'subsample': [0.6, 0.8, 1.0],\n",
    "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "              'max_depth': [3, 4, 5]}\n",
    "\n",
    "clf = GridSearchCV(xgb.XGBRegressor(), parameters, cv=3, n_jobs=8, verbose=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"learning_rate\": [0.001, 0.01, 0.05, 0.1],\n",
    "    \"min_samples_split\": [5, 10, 30, 50],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"max_features\": [\"log2\", \"sqrt\"],\n",
    "    \"subsample\": [0.8, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\": [500, 1000, 5000]\n",
    "    }\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingRegressor(), parameters, cv=3, n_jobs=8, verbose=10)\n",
    "\n",
    "clf.fit(X_encoded_train, y_encoded_train)\n",
    "print(clf.score(X_encoded_train, y_encoded_train))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 441621835382.0202, tolerance: 719132949.9230078\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, max_iter=100000, random_state=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = ElasticNet(random_state=0, max_iter=100000, alpha=0.1, l1_ratio=0.5)\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 21552.193426189027\n",
      "Mean Squared Error: 2287130520.622509\n",
      "Root Mean Squared Error: 47823.95341899819\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = regr.predict(test_dataset.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Id': test_id, 'SalePrice': test_pred})\n",
    "df.to_csv('elastic-net-all-encoded-column-tuned.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net Grid Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:   47.6s\n",
      "[Parallel(n_jobs=8)]: Done  68 out of  75 | elapsed:   55.1s remaining:    5.7s\n",
      "[Parallel(n_jobs=8)]: Done  75 out of  75 | elapsed:   59.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8777144413375937\n",
      "{'alpha': 0.1, 'l1_ratio': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 441621835382.0202, tolerance: 719132949.9230078\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha': [0, 0.5, 0.1, 0.01, 0.001],\n",
    "                                'l1_ratio': [0, 0.25, 0.5, 0.75, 1]}\n",
    "\n",
    "clf = GridSearchCV(ElasticNet(random_state=0, max_iter=100000), parameters, cv=3, n_jobs=8, verbose=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
